Predicting_Employee_RetentionPredicting_Employee_Retention
# Employee Retention Logistic Regression – End-to-end script
import os, numpy as np, pandas as pd, matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import RFE
from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, precision_score, recall_score, precision_recall_curve

DATA_PATH = "Employee_data.csv"
OUT_DIR = "employee_retention_outputs"
os.makedirs(OUT_DIR, exist_ok=True)

df = pd.read_csv(DATA_PATH)
df.columns = [c.strip().replace('\n', ' ').replace('\r', ' ') for c in df.columns]
df['Attrition'] = df['Attrition'].map({'Left': 1, 'Stayed': 0})

y = df['Attrition']
X = df.drop(columns=['Attrition', 'Employee ID']) if 'Employee ID' in df.columns else df.drop(columns=['Attrition'])

num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = X.select_dtypes(include=['object']).columns.tolist()

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)

numeric_pipe = Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])
categorical_pipe = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),
                             ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first', sparse=False))])
preprocessor = ColumnTransformer([('num', numeric_pipe, num_cols), ('cat', categorical_pipe, cat_cols)], remainder='drop')

# Baseline
baseline_clf = LogisticRegression(max_iter=2000, class_weight='balanced', solver='liblinear')
baseline_pipe = Pipeline([('preprocess', preprocessor), ('clf', baseline_clf)])
baseline_pipe.fit(X_train, y_train)
val_proba_base = baseline_pipe.predict_proba(X_val)[:,1]
val_pred_base = (val_proba_base >= 0.5).astype(int)

# RFE on sample -> final model on selected features
X_train_transformed = preprocessor.fit_transform(X_train)
X_val_transformed = preprocessor.transform(X_val)

try:
    ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']
    ohe_feature_names = ohe.get_feature_names_out(cat_cols).tolist()
except Exception:
    ohe_feature_names = []
feature_names = num_cols + ohe_feature_names

idx = np.random.RandomState(42).choice(len(X_train_transformed), size=min(10000, len(X_train_transformed)), replace=False)
X_train_sample = X_train_transformed[idx]
y_train_sample = y_train.iloc[idx].values

k_features = min(30, X_train_transformed.shape[1]//2 if X_train_transformed.shape[1] > 2 else 1)
rfe = RFE(LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear'),
          n_features_to_select=k_features, step=0.2)
rfe.fit(X_train_sample, y_train_sample)

mask = rfe.get_support()
selected_features = [n for n, m in zip(feature_names, mask) if m]

X_train_sel = X_train_transformed[:, mask]
X_val_sel = X_val_transformed[:, mask]

final = LogisticRegression(max_iter=2000, class_weight='balanced', solver='liblinear')
final.fit(X_train_sel, y_train)

# Optimal cutoff (Youden J)
train_proba = final.predict_proba(X_train_sel)[:,1]
fpr, tpr, thr = roc_curve(y_train, train_proba)
opt_idx = np.argmax(tpr - fpr)
opt_cutoff = thr[opt_idx]

val_proba = final.predict_proba(X_val_sel)[:,1]
val_pred = (val_proba >= opt_cutoff).astype(int)

acc = accuracy_score(y_val, val_pred)
prec = precision_score(y_val, val_pred)
rec = recall_score(y_val, val_pred)
auc = roc_auc_score(y_val, val_proba)
tn, fp, fn, tp = confusion_matrix(y_val, val_pred).ravel()
spec = tn / (tn + fp)

out = {
    'optimal_cutoff': float(opt_cutoff),
    'accuracy': float(acc),
    'precision': float(prec),
    'recall_sensitivity': float(rec),
    'specificity': float(spec),
    'roc_auc': float(auc),
    'confusion_matrix': [[int(tn), int(fp)], [int(fn), int(tp)]],
    'baseline_accuracy@0.5': float(accuracy_score(y_val, val_pred_base)),
    'baseline_precision@0.5': float(precision_score(y_val, val_pred_base)),
    'baseline_recall@0.5': float(recall_score(y_val, val_pred_base)),
    'baseline_auc': float(roc_auc_score(y_val, val_proba_base)),
    'selected_features': selected_features
}
pd.Series(out, dtype=object).to_json(os.path.join(OUT_DIR, 'validation_metrics.json'), indent=2)

pd.DataFrame({'Attrition_Prob': val_proba, 'Attrition_Pred': val_pred}).to_csv(os.path.join(OUT_DIR, 'validation_predictions.csv'), index=False)

print("Done. Metrics JSON at:", os.path.join(OUT_DIR, 'validation_metrics.json'))

